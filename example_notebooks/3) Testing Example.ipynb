{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Evaluating and Running Decoders\n",
    "\n",
    "Now that we know how to train a decoder, we would like to see how to evaluate the performance of that decoder, as well as how to use the decoder in a production setting. In this notebook we will demonstrate how to perform both of these tasks.\n",
    "\n",
    "##### 3a) Evaluating a Trained Decoder\n",
    "\n",
    "Given a trained decoder we would of course like to benchmark the decoder to evaluate how well it performs. This procedure is very similar to training the decoder, in that we run multiple decoding episodes in which the agent interacts with the environment until it \"dies\" - however in this context we would like the agent to use only a greedy policy for action selection, i.e. to never make random moves, and we do not need to update the agents parameters in time. As we will see benchmarking an agent is made easy by use of the DQNAgent class \"test\" method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we begin by importing the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import gym\n",
    "import keras\n",
    "import numpy as np\n",
    "import rl as rl\n",
    "import tensorflow\n",
    "from Environments import *\n",
    "from Function_Library import *\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.callbacks import FileLogger\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import (\n",
    "    BoltzmannQPolicy,\n",
    "    EpsGreedyQPolicy,\n",
    "    GreedyQPolicy,\n",
    "    LinearAnnealedPolicy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to load:\n",
    "    \n",
    "   1. The hyper-parameters of the agent we would like to test\n",
    "   2. The weights of the agent\n",
    "    \n",
    "In this example we will evaluate one of the provided pre-trained decoders, for d=5, with X noise only, trained at an error rate of p_phys=p_meas=0.007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_model='x'\n",
    "fixed_configs_path = os.path.join(os.getcwd(), f\"../trained_models/d5_{error_model}/fixed_config.p\")\n",
    "variable_configs_path = os.path.join(\n",
    "    os.getcwd(), f\"../trained_models/d5_{error_model}/0.007/variable_config_77.p\"\n",
    ")\n",
    "model_weights_path = os.path.join(\n",
    "    os.getcwd(), f\"../trained_models/d5_{error_model}/0.007/final_dqn_weights.h5f\"\n",
    ")\n",
    "\n",
    "static_decoder_path = os.path.join(os.getcwd(), \"referee_decoders/nn_d5_X_p5\")\n",
    "static_decoder = load_model(static_decoder_path)\n",
    "\n",
    "fixed_configs = pickle.load(open(fixed_configs_path, \"rb\"))\n",
    "variable_configs = pickle.load(open(variable_configs_path, \"rb\"))\n",
    "\n",
    "all_configs = {}\n",
    "\n",
    "for key in fixed_configs.keys():\n",
    "    all_configs[key] = fixed_configs[key]\n",
    "\n",
    "for key in variable_configs.keys():\n",
    "    all_configs[key] = variable_configs[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can instantiate the environment in which we will test the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Surface_Code_Environment_Multi_Decoding_Cycles(\n",
    "    d=all_configs[\"d\"],\n",
    "    p_phys=all_configs[\"p_phys\"],\n",
    "    p_meas=all_configs[\"p_meas\"],\n",
    "    error_model=all_configs[\"error_model\"],\n",
    "    use_Y=all_configs[\"use_Y\"],\n",
    "    volume_depth=all_configs[\"volume_depth\"],\n",
    "    static_decoder=static_decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build a model and instantiate an agent with all the parameters of the pre-trained agent. Notice that we insist on a greedy policy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_convolutional_nn(\n",
    "    all_configs[\"c_layers\"],\n",
    "    all_configs[\"ff_layers\"],\n",
    "    env.observation_space.shape,\n",
    "    env.num_actions,\n",
    ")\n",
    "memory = SequentialMemory(limit=all_configs[\"buffer_size\"], window_length=1)\n",
    "policy = GreedyQPolicy(masked_greedy=True)\n",
    "test_policy = GreedyQPolicy(masked_greedy=True)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "\n",
    "dqn = DQNAgent(\n",
    "    model=model,\n",
    "    nb_actions=env.num_actions,\n",
    "    memory=memory,\n",
    "    nb_steps_warmup=all_configs[\"learning_starts\"],\n",
    "    target_model_update=all_configs[\"target_network_update_freq\"],\n",
    "    policy=policy,\n",
    "    test_policy=test_policy,\n",
    "    gamma=all_configs[\"gamma\"],\n",
    "    enable_dueling_network=all_configs[\"dueling\"],\n",
    ")\n",
    "\n",
    "\n",
    "dqn.compile(Adam(lr=all_configs[\"learning_rate\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage the agent has random weights, and so we load in the weights of the pre-trained agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.model.load_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now finally we can benchmark the agent using the test method. \n",
    "\n",
    "It is important to note that the reported episode length is the number of _non-trivial_ syndrome volumes that the agent received, as these are the steps during which a decision needs to be taken on the part of the agent. The qubit lifetime, whose rolling average is reported, is the total number of syndrome measurements (between which an error may occur) for which the agent survived, as this is the relevant metric to compare with a single faulty qubit whose expected lifetime is 1/(error_probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 1001 episodes ...\n",
      "-----------------\n",
      "Episode: 1\n",
      "This Episode Length: 8\n",
      "This Episode Reward: 4.0\n",
      "This Episode Lifetime: 25\n",
      "\n",
      "Episode Lifetimes Avg: 25.000\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_423691/3781717103.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msingle_cycle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/envs/deepq/lib/python3.7/site-packages/keras_rl-0.4.2-py3.7.egg/rl/core.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, env, nb_episodes, action_repetition, callbacks, visualize, nb_max_episode_steps, nb_max_start_steps, start_step_policy, verbose, episode_averaging_length, interval, single_cycle)\u001b[0m\n\u001b[1;32m    535\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_repetition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_action_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m                     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m                     \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University/Master/Thesis/Code/DeepQ-Decoding/example_notebooks/Environments.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mcorrect_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_one_hot_labels_surface_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mdecoder_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_true_syndrome_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepq/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/miniconda3/envs/deepq/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepq/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3251\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3253\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3254\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3255\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepq/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepq/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepq/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   5650\u001b[0m       with super(_DefaultGraphStack,\n\u001b[1;32m   5651\u001b[0m                  self).get_controller(default) as g, context.graph_mode():\n\u001b[0;32m-> 5652\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5653\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5654\u001b[0m       \u001b[0;31m# If an exception is raised here it may be hiding a related exception in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_test_episodes = 1001\n",
    "testing_history = dqn.test(\n",
    "    env,\n",
    "    nb_episodes=nb_test_episodes,\n",
    "    visualize=False,\n",
    "    verbose=2,\n",
    "    interval=100,\n",
    "    single_cycle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = testing_history.history[\"episode_lifetime\"]\n",
    "\n",
    "print(\"Mean Qubit Lifetime:\", np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that on average, over 1001 test episodes, the qubit survives for 329 syndrome measurements on average, which is better than the average lifetime of 143 syndrome measurements for a single faulty qubit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b) Using a Trained Decoder in Production\n",
    "\n",
    "In addition to benchmarking a decoder via the agent test method, we would like to demonstrate how to use the decoder in practice, given a faulty syndrome volume. In principle all the information on how to do this is contained within the environments and test method, but to aid in applying these decoders quickly and easily in practice we make everything explicit here:\n",
    "\n",
    "To do this, we start by generating a faulty syndrome volume as would be generated by an experiment or in the process of a quantum computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 5\n",
    "p_phys = 0.009\n",
    "p_meas = p_phys\n",
    "error_model = \"DP\"\n",
    "qubits = generateSurfaceCodeLattice(d)\n",
    "\n",
    "hidden_state = np.zeros((d, d), int)\n",
    "faulty_syndromes = []\n",
    "\n",
    "for j in range(d):\n",
    "    error = generate_error(d, p_phys, error_model)\n",
    "    hidden_state = obtain_new_error_configuration(hidden_state, error)\n",
    "    current_true_syndrome = generate_surface_code_syndrome_NoFT_efficient(\n",
    "        hidden_state, qubits\n",
    "    )\n",
    "    current_faulty_syndrome = generate_faulty_syndrome(current_true_syndrome, p_meas)\n",
    "    faulty_syndromes.append(current_faulty_syndrome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By viewing the final hidden_state (the lattice state) we can see what errors occured, which here was a single error on the 21st qubit (we start counting from 0, and move row wise left to right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Last error that was applied\n",
    "print(error)\n",
    "# Hidden state after d-measurement/-error rounds\n",
    "print(hidden_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can view the faulty_syndromes that we received, which is what would come out of an experiment. As we can see, measurement errors occured in syndrome slices 2 and 5, and it appears as if the actual error occured between extraction of syndrome 2 and 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syndrome slice 1\n",
      "\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "\n",
      "syndrome slice 2\n",
      "\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "\n",
      "syndrome slice 3\n",
      "\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "\n",
      "syndrome slice 4\n",
      "\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "\n",
      "syndrome slice 5\n",
      "\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in range(d):\n",
    "    print(\"syndrome slice\", j + 1)\n",
    "    print()\n",
    "    print(faulty_syndromes[j])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we would like to decode and obtain the suggested corrections. To do this, we begin by padding the faulty syndromes as required and by concatenating the obtained volume with an action history slice, in which all the actions are initially zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize a zero'd input volume\n",
    "input_state = np.zeros((d + 1, 2 * d + 1, 2 * d + 1), int)\n",
    "\n",
    "# embed and place the faulty syndrome slices in the correct place\n",
    "for j in range(d):\n",
    "    input_state[j, :, :] = env.padding_syndrome(faulty_syndromes[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can run the agent, collecting the suggested actions, until the agent does the identity, which suggests that it is finished decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = []\n",
    "\n",
    "still_decoding = True\n",
    "while still_decoding:\n",
    "\n",
    "    # Fetch the suggested correction\n",
    "    action = dqn.forward(input_state)\n",
    "\n",
    "    if action not in corrections and action != env.identity_index:\n",
    "        # If the action has not yet been done, or is not the identity\n",
    "\n",
    "        # append the suggested correction to the list of corrections\n",
    "        corrections.append(action)\n",
    "\n",
    "        # Update the input state to the agent to indicate the correction it would have made\n",
    "        input_state[d, :, :] = env.padding_actions(corrections)\n",
    "\n",
    "    else:\n",
    "        # decoding should stop\n",
    "        still_decoding = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can view the suggested corrections, which in this case was a single correct suggestion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n"
     ]
    }
   ],
   "source": [
    "print(corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before correction:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After correction:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Utils import *\n",
    "\n",
    "print(\"Before correction:\")\n",
    "draw_surface_code(hidden_state, env.syndromes, current_true_syndrome, env.d, corrections=None)\n",
    "plt.show()\n",
    "\n",
    "corrected_state = np.zeros((d, d), int)\n",
    "corrections_coords = []\n",
    "for correction in corrections:\n",
    "    col = correction % d\n",
    "    row = (correction - col) // d\n",
    "    corrected_state[row, col] = 1\n",
    "    corrections_coords.append((row,col))\n",
    "new_hidden_state = obtain_new_error_configuration(hidden_state, corrected_state)\n",
    "new_true_syndrome = generate_surface_code_syndrome_NoFT_efficient(\n",
    "    new_hidden_state, qubits\n",
    ")\n",
    "\n",
    "print(\"After correction:\")\n",
    "draw_surface_code(\n",
    "    new_hidden_state, env.syndromes, new_true_syndrome, env.d, corrections=corrections_coords\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in general if there is more than one error, or if the agent is uncertain about a given configuration, it may choose to do the identity, therefore triggering a new syndrome volume from which it may be more certain which action to take - The crucial point is that in practice we are interested in how long the qubit survives for, and an optimal strategy for achieving long qubit lifetimes may not be to attempt to fully decode into the ground state after each syndrome volume!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepq",
   "language": "python",
   "name": "deepq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
